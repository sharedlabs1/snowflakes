= Lab 31: Optimizing Large-Scale Data Partitioning and Clustering in Snowflake  


== Objective
In this lab, you will learn how to optimize queries on large-scale datasets in Snowflake using partitioning and clustering, ensuring efficient query execution and minimal resource usage.

== Prerequisites
- Snowflake account access.
- Large dataset loaded in Snowflake (at least several million rows).

== Steps
1. **Loading a Large Dataset**
   . If not already loaded, load a large dataset into Snowflake (use sample datasets or Snowflake-provided public datasets).

[source,sql]
----
   CREATE OR REPLACE TABLE large_sales_data (
     id INT, 
     amount DECIMAL(10, 2), 
     sale_date DATE, 
     region STRING
   );
   INSERT INTO large_sales_data 
   SELECT SEQ8(), RAND() * 1000, CURRENT_DATE() - SEQ8(), 'Region ' || RAND()::INT
   FROM TABLE(GENERATOR(ROWCOUNT => 10000000));
----

2. **Querying the Dataset**
   . Run a simple query to retrieve a small subset of the data:
   
[source,sql]
----
SELECT * FROM large_sales_data WHERE sale_date > '2023-01-01';
----

3. **Reviewing Query Performance**
   . Use the **QUERY_HISTORY** view to examine query performance metrics:

[source,sql]
----
SELECT * FROM QUERY_HISTORY WHERE QUERY_TEXT ILIKE '%large_sales_data%';
----

4. **Creating Clustering Keys**
   . Add a clustering key to the table to improve performance for queries based on `sale_date`:
   
[source,sql]
----
   
ALTER TABLE large_sales_data CLUSTER BY (sale_date);
----

5. **Checking Clustering Information**
   . Use the **CLUSTERING_INFORMATION** view to check the effectiveness of clustering:
   
[source,sql]
----
SELECT * FROM CLUSTERING_INFORMATION WHERE TABLE_NAME = 'LARGE_SALES_DATA';
----

6. **Optimizing Clustering with Reclustering**
   . Trigger manual reclustering for the table:
   
[source,sql]
----
ALTER TABLE large_sales_data RECLUSTER;
----

7. **Partitioning the Data**
   . Create a new partitioned table based on `region` and `sale_date`:
   
[source,sql]
----
   CREATE OR REPLACE TABLE partitioned_sales_data (
     id INT, 
     amount DECIMAL(10, 2), 
     sale_date DATE, 
     region STRING
   ) PARTITION BY (region);
----

8. **Loading Data into Partitioned Table**
   . Load data into the new partitioned table:
   
[source,sql]
----
   INSERT INTO partitioned_sales_data SELECT * FROM large_sales_data;
----

9. **Querying the Partitioned Data**
   . Query the partitioned table using conditions on `region`:
   
[source,sql]
----
   SELECT * FROM partitioned_sales_data WHERE region = 'Region 5';
----

10. **Checking Partition Pruning**
   . Check if partition pruning is being applied by reviewing query plans:
  
[source,sql]
 ----
   EXPLAIN SELECT * FROM partitioned_sales_data WHERE region = 'Region 5';
 ----

11. **Creating Compound Clustering Keys**
   . Create compound clustering keys on both `region` and `sale_date` for the partitioned table:
  
[source,sql]
 ----
   ALTER TABLE partitioned_sales_data CLUSTER BY (region, sale_date);
----

12. **Testing Queries on Clustered Data**
   . Query the clustered data using conditions on both `region` and `sale_date` to test the performance:
  
[source,sql]
 ----
   SELECT * FROM partitioned_sales_data WHERE region = 'Region 5' AND sale_date > '2023-06-01';
  ----

13. **Monitoring Query Improvement**
   . Compare query execution times before and after clustering using the **QUERY_HISTORY** view:
   
[source,sql]
----
   SELECT * FROM QUERY_HISTORY WHERE QUERY_TEXT ILIKE '%partitioned_sales_data%';
----

14. **Analyzing Storage and Performance Trade-offs**
   . Use the **TABLE_STORAGE_METRICS** view to analyze the storage costs and benefits of clustering and partitioning:
  
[source,sql]
----
   SELECT * FROM TABLE_STORAGE_METRICS WHERE TABLE_NAME = 'PARTITIONED_SALES_DATA';
----

15. **Automating Clustering and Partitioning Maintenance**
   . Set up Snowflake tasks to automate reclustering on a scheduled basis:
   
[source,sql]
----
   CREATE OR REPLACE TASK auto_recluster_task
   WAREHOUSE = 'COMPUTE_WH'
   SCHEDULE = '1 DAY'
   AS
   ALTER TABLE partitioned_sales_data RECLUSTER;
----

== Conclusion
- You have successfully optimized large-scale datasets in Snowflake using partitioning and clustering, ensuring efficient query performance and minimal resource usage.
