= Lab 23: Snowflake Continuous Data Integration with Snowpipe  


== Objective
In this lab, you will use Snowpipe for continuous data loading into Snowflake, allowing you to automate data ingestion from external sources as new data arrives.

== Prerequisites
- Snowflake account access.
- Sample external data source (e.g., AWS S3 bucket).

== Steps

1. **Creating a Stage for Snowpipe**
   . Create a Snowflake stage to store files that will be continuously loaded:

[source,sql]
----
CREATE OR REPLACE STAGE my_snowpipe_stage URL='s3://your-bucket-name/path/' 
CREDENTIALS=(AWS_KEY_ID='your_key_id' AWS_SECRET_KEY='your_secret_key');
----


2. **Creating a Table to Load Data Into**
. Create a table to hold the continuously loaded data:

[source,sql]
----
CREATE TABLE sales_continuous (id INT, sale_amount DECIMAL(10, 2), sale_date DATE);
----


3. **Creating a Snowpipe for Continuous Loading**
. Define a Snowpipe to continuously load data from the external stage:

[source,sql]
----
CREATE OR REPLACE PIPE my_snowpipe AS COPY INTO sales_continuous FROM @my_snowpipe_stage FILE_FORMAT = (TYPE = 'CSV');
----


4. **Configuring Automated Ingestion**
. Configure automatic ingestion triggers for Snowpipe using cloud provider integration (e.g., AWS Lambda or Azure Functions).

5. **Monitoring Snowpipe**
. Monitor the Snowpipe process to ensure continuous data ingestion:

[source,sq]
----
SELECT * FROM PIPE_USAGE_HISTORY WHERE PIPE_NAME = 'MY_SNOWPIPE';
----


== Conclusion
- You have successfully configured Snowpipe for continuous data integration, allowing new data from external sources to be automatically ingested into Snowflake.

